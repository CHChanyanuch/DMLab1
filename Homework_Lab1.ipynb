{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary for when working with external scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the documents containing the categories provided\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, \\\n",
    "                                  shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look in some records\n",
    "twenty_train.data[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for names\n",
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find lenght of data\n",
    "len(twenty_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(twenty_train.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can print the sample of what subset contains\n",
    "# An example of what the subset contains\n",
    "# split by \"\\n\"\n",
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give example the labels\n",
    "print(twenty_train.target_names[twenty_train.target[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the category of dacuments via target key values\n",
    "# category of first 10 documents.\n",
    "twenty_train.target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out target name in first 10\n",
    "\n",
    "for t in twenty_train.target[:10]: # dataset.target\n",
    "    print(twenty_train.target_names[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >>> Exercise 1\n",
    "\n",
    "In this exercise, please print out the text data for the first three samples in the dataset. (See the above code for help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer [Done]\n",
    "\n",
    "for t in twenty_train.data[:3]: # dataset.data\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation Section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dictionary into Pandas Dataframe\n",
    "# show data\n",
    "twenty_train.data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "# import helpers \n",
    "\n",
    "import pandas as pd # manipulate objects define pandas\n",
    "\n",
    "# my functions\n",
    "import helpers.data_mining_helpers as dmh \n",
    "# folder called helper it has some function implementated\n",
    "# dmh data mining helper\n",
    "# doc1,doc2,doc3\n",
    "# construct dataframe from a list\n",
    "# create dataframe which will take 20 format into rows \n",
    "# become text column\n",
    "# doc1\n",
    "# doc2\n",
    "# doc3\n",
    "X = pd.DataFrame.from_records(dmh.format_rows(twenty_train), columns= ['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)\n",
    "# check we did not lose any data\n",
    "# exactly the same as len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the dataframe, we named col = text\n",
    "# get in DataFrame format\n",
    "X[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "for t in X[\"text\"][:3]:\n",
    "    print(t)\n",
    "# diff way to print from data structure\n",
    "# print data in text col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding col = category\n",
    "# add category to the dataframe\n",
    "# x include categoty  if it no column it means create it\n",
    "\n",
    "X['category'] = twenty_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add category label also\n",
    "X['category_name'] = X.category.apply(lambda t: dmh.format_labels(t, twenty_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show\n",
    "X[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple query\n",
    "X[0:10][[\"text\", \"category_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query from last [order by desc] query last 10 records\n",
    "X[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query every 10 records\n",
    "# iloc allows us to query a selection of our dataset by position.\n",
    "\n",
    "# using loc (by position)\n",
    "X.iloc[::10, 0:2][0:10] \n",
    "\n",
    "# every 10, first 2 column , limit the amount want to see (10 results be displayed)\n",
    "# query specific things by function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc function to define col you want to query\n",
    "# using loc (by label)\n",
    "X.loc[::10, 'text'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard query \n",
    "# (Cannot simultaneously select rows and columns)\n",
    "X[::10][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >>> Exercise 2\n",
    "Experiment with other querying techniques using pandas dataframes. Refer to their documentation for more information.\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "X.describe()\n",
    "# X[0:10][[\"text\"]]\n",
    "# X[[\"text\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** >>> Exercise 3 (5 min): **  \n",
    "Try to fecth records belonging to the ```comp.graphics``` category, and query every 10th record. Only show the first 5 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "# X[X['category_name']==sci.med].iloc[::10][0:5]\n",
    "X.loc[lambda f: f.category_name == 'comp.graphics'].iloc[::10, :][0:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining using PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values .isnull()\n",
    "# X.isnull()\n",
    "X.isnull().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let using isnull function with each category and summarize it\n",
    "X.isnull().apply(lambda x: dmh.check_missing_values(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >>> Exercise 4\n",
    "Let's try something different. Instead of calculating missing values by column let's try to calculate the missing values in every record instead of every column.\n",
    "\n",
    "ùêªùëñùëõùë°\n",
    "H\n",
    "i\n",
    "n\n",
    "t\n",
    "  : axis parameter. Check the documentation for more information\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "# using axis\n",
    "# axis = 0 = column\n",
    "# X.isnull().apply(lambda x: dmh.check_missing_values(x), axis=0)\n",
    "# axis = 1 = row\n",
    "X.isnull().apply(lambda x: dmh.check_missing_values(x), axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Data\n",
    "We will insert a Series, which is basically a \"one-dimensional labeled array capable of holding data of any type (integer, string, float, python objects, etc.). The axis labels are collectively called index.\", into our current dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_series = pd.Series([\"dummy_record\", 1], index=[\"text\", \"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.append [append ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ]\n",
    "result_with_series = X.append(dummy_series, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the records was commited into result\n",
    "\n",
    "# before that it return 2257 \n",
    "# after we add dummy record it return 2258 instead\n",
    "\n",
    "len(result_with_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_with_series.isnull().apply(lambda x: dmh.check_missing_values(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy record as dictionary format\n",
    "dummy_dict = [{'text': 'dummy_record',\n",
    "               'category': 1\n",
    "              }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÄ‡∏û‡∏¥‡πà‡∏° dummy_dict ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô X\n",
    "X = X.append(dummy_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ô‡∏±‡∏ö‡πÉ‡∏´‡∏°‡πà\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().apply(lambda x: dmh.check_missing_values(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dropna(inplace=True)\n",
    "# drop the missing value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().apply(lambda x: dmh.check_missing_values(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ô‡∏±‡∏ö‡πÉ‡∏´‡∏°‡πà\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 (take home)\n",
    "\n",
    "There is an old saying that goes, \"The devil is in the details.\" When we are working with extremely large data, it's difficult to check records one by one (as we have been doing so far). And also, we don't even know what kind of missing values we are facing. Thus, \"debugging\" skills get sharper as we spend more time solving bugs. Let's focus on a different method to check for missing values and the kinds of missing values you may encounter. It's not easy to check for missing values as you will find out in a minute.\n",
    "\n",
    "Please check the data and the process below, describe what you observe and why it happened.   \n",
    "$Hint$ :  why `.isnull()` didn't work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "NA_dict = [{ 'id': 'A', 'missing_example': np.nan },\n",
    "           { 'id': 'B'                    },\n",
    "           { 'id': 'C', 'missing_example': 'NaN'  },\n",
    "           { 'id': 'D', 'missing_example': 'None' },\n",
    "           { 'id': 'E', 'missing_example':  None  },\n",
    "           { 'id': 'F', 'missing_example': ''     }]\n",
    "\n",
    "NA_df = pd.DataFrame(NA_dict, columns = ['id','missing_example'])\n",
    "NA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NA_df['missing_example'].isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer here\n",
    "\n",
    "In missing_example column A,B,C it display the same NaN \n",
    "but after checking missing value using [isnull] \n",
    "the return value is not the same \n",
    "it show that C = False. C is not null.\n",
    "\n",
    "In missing_example column D,E it display the same None\n",
    "but after checking missing value using [isnull] \n",
    "the return value is not the same \n",
    "it show that D = False. D is not null.\n",
    "it show that E = True. E is null.\n",
    "\n",
    "In missing_example column D it display nothing\n",
    "but after checking missing value using [isnull] \n",
    "it return False. F is not null.\n",
    "\n",
    "Why C,D,F is not null may because when we input the data to NA_df\n",
    "the system may seen those input value as [String] value\n",
    "that why when checking with [isnull] it return False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X.duplicated('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏•‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà duplicate / ‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏≠‡∏á‡∏•‡∏ö\n",
    "dummy_duplicate_dict = [{\n",
    "                             'text': 'dummy record',\n",
    "                             'category': 1, \n",
    "                             'category_name': \"dummy category\"\n",
    "                        },\n",
    "                        {\n",
    "                             'text': 'dummy record',\n",
    "                             'category': 1, \n",
    "                             'category_name': \"dummy category\"\n",
    "                        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÄ‡∏≠‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô X\n",
    "X = X.append(dummy_duplicate_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X.duplicated('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop_duplicates(keep=False, inplace=True) \n",
    "# inplace applies changes directly on our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X.sample(n=1000) #random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6 (take home)\n",
    "Notice any changes to the `X` dataframe? What are they? Report every change you noticed as compared to the previous state of `X`. Feel free to query and look more closely at the dataframe for these changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer here\n",
    "There are no changes to 'X' dataframe\n",
    "because we crete 'X_sample' dataframe.\n",
    "We get only 1000 ramdom data from 'X' dataframe\n",
    "so, we do not make any changes to 'X' dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check X dataframe\n",
    "X[1035:1040]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check X dataframe - still 2257\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's take a loot at the magic of matplotlib below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.category_name.value_counts())\n",
    "\n",
    "# plot barchart for X_sample\n",
    "X.category_name.value_counts().plot(kind = 'bar',\n",
    "                                    title = 'Category distribution',\n",
    "                                    ylim = [0, 650],        \n",
    "                                    rot = 0, fontsize = 11, figsize = (8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_sample.category_name.value_counts())\n",
    "\n",
    "# plot barchart for X_sample\n",
    "X_sample.category_name.value_counts().plot(kind = 'bar',\n",
    "                                           title = 'Category distribution',\n",
    "                                           ylim = [0, 300], \n",
    "                                           rot = 0, fontsize = 12, figsize = (8,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use following command to see other available styles to prettify your charts.\n",
    "```python\n",
    "print(plt.style.available)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_no = X_sample.category_name.value_counts().max()\n",
    "print(y_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >>> **Exercise 7 (5 min):**\n",
    "Notice that for the `ylim` parameters we hardcoded the maximum value for y. Is it possible to automate this instead of hard-coding it? How would you go about doing that? (Hint: look at code above for clues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "import math\n",
    "\n",
    "def roundup(x):\n",
    "    return int(math.ceil(x / 100.0)) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "\n",
    "print(X.category_name.value_counts())\n",
    "# plot barchart for X_sample\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á y_no\n",
    "y_no = X.category_name.value_counts().max()\n",
    "#y_no = X_sample.category_name.value_counts().max()\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á bar chart\n",
    "X.category_name.value_counts().plot(kind = 'bar',\n",
    "                                           title = 'Category distribution',\n",
    "                                           ylim = [0,roundup(y_no)], \n",
    "                                           rot = 0, fontsize = 12, figsize = (8,3))\n",
    "\n",
    "# X_sample.category_name.value_counts().plot(kind = 'bar',\n",
    "#                                            title = 'Category distribution',\n",
    "#                                            ylim = [0,roundup(y_no)], \n",
    "#                                            rot = 0, fontsize = 12, figsize = (8,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >>> **Exercise 8 (take home):** \n",
    "We can also do a side-by-side comparison of the distribution between the two datasets, but maybe you can try that as an excerise. Below we show you an snapshot of the type of chart we are looking for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = categories\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set width of bar\n",
    "barWidth = 0.4\n",
    "plt.rcParams[\"figure.figsize\"] = [12,9]\n",
    "\n",
    "\n",
    "r1 = np.arange(len(index))\n",
    "r2 = [x + barWidth for x in r1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xc = X.category_name.value_counts()\n",
    "Xs = X_sample.category_name.value_counts()\n",
    "print(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the bar chart\n",
    "plt.bar(r1, Xc, width=barWidth,  label='X')\n",
    "plt.bar(r2, Xs, color='darkorange', width=barWidth,  label='X_sample')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "\n",
    "plt.xticks(r1 , index)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a like a minute or two to process\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á col unigram ‡πÉ‡∏ä‡πâ dmh.tokenize_text()\n",
    "X['unigrams'] = X['text'].apply(lambda x: dmh.tokenize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0:4][\"unigrams\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏î‡∏π‡πÅ‡∏Ñ‡πà row ‡πÅ‡∏£‡∏Å\n",
    "list(X[0:1]['unigrams'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       From: sd345@city.ac.uk (Michael Collier) Subje...\n",
       "1       From: ani@ms.uky.edu (Aniruddha B. Deglurkar) ...\n",
       "2       From: djohnson@cs.ucsd.edu (Darin Johnson) Sub...\n",
       "3       From: s0612596@let.rug.nl (M.M. Zwart) Subject...\n",
       "4       From: stanly@grok11.columbiasc.ncr.com (stanly...\n",
       "                              ...                        \n",
       "2252    From: roos@Operoni.Helsinki.FI (Christophe Roo...\n",
       "2253    From: mhollowa@ic.sunysb.edu (Michael Holloway...\n",
       "2254    From: sasghm@theseus.unx.sas.com (Gary Merrill...\n",
       "2255    From: Dan Wallach <dwallach@cs.berkeley.edu> S...\n",
       "2256    From: dyer@spdcc.com (Steve Dyer) Subject: Re:...\n",
       "Name: text, Length: 2257, dtype: object"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(X.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze = count_vect.build_analyzer()\n",
    "analyze(\"Hello World!\")\n",
    "#\" \".join(list(X[4:5].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >>> Exercise 9\n",
    "Let's analyze the first record of our X dataframe with the new analyzer we have just built. Go ahead try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "\n",
    "\n",
    "#X_1st_counts = count_vect.fit_transform(X[0:1].text)\n",
    "# X_1st_counts.shape \n",
    "# count_vect.vocabulary_\n",
    "\n",
    "analyze = count_vect.build_analyzer()\n",
    "analyze(\" \".join(list(X[0:1].text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us look at the term-document matrix we built above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can check the shape of this matrix by:\n",
    "X_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['071', '0hb', '14', '477', '8000', '8565', 'ac', 'advance', 'also', 'any']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can obtain the feature names of the vectorizer, i.e., the terms\n",
    "# usually on the horizontal axis\n",
    "count_vect.get_feature_names()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we convert from sparse array to normal array\n",
    "X_counts[0:5, 0:100].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **>>> Exercise 10 (take home):**\n",
    "We said that the `1` at the beginning of the fifth record represents the `00` term. Notice that there is another 1 in the same record. Can you provide code that can verify what word this 1 represents from the vocabulary. Try to do this as efficient as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_vect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c8ef476d284c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count_vect' is not defined"
     ]
    }
   ],
   "source": [
    "feature_names = count_vect.get_feature_names()\n",
    "\n",
    "pd.DataFrame(X_counts[0:5, 0:100].toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_counts = count_vect.fit_transform(X.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "count_vect not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-8380862f7965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: count_vect not found"
     ]
    }
   ],
   "source": [
    "X_counts.count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    From: sd345@city.ac.uk (Michael Collier) Subje...\n",
       "1    From: ani@ms.uky.edu (Aniruddha B. Deglurkar) ...\n",
       "2    From: djohnson@cs.ucsd.edu (Darin Johnson) Sub...\n",
       "3    From: s0612596@let.rug.nl (M.M. Zwart) Subject...\n",
       "4    From: stanly@grok11.columbiasc.ncr.com (stanly...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X[4:5]\n",
    "X['text'][0:5][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[4:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vect.transform('00'+X[4:5]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
